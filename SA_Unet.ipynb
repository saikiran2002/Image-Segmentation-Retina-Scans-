{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c612c0d2-6872-44b2-a3bc-b460f2b51136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T02:07:54.037926Z",
     "iopub.status.busy": "2024-04-27T02:07:54.037384Z",
     "iopub.status.idle": "2024-04-27T02:07:54.864454Z",
     "shell.execute_reply": "2024-04-27T02:07:54.864118Z",
     "shell.execute_reply.started": "2024-04-27T02:07:54.037879Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "import sys\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ConfusionMatrix:\n",
    "    def __init__(self, num_classes,device):\n",
    "        self.num_classes = num_classes\n",
    "        self.mat = torch.zeros((num_classes, num_classes), dtype=torch.int64,device=device)\n",
    "\n",
    "    def update(self, a, b):\n",
    "        n = self.num_classes\n",
    "        with torch.no_grad():\n",
    "            mask = (a >= 0) & (a < n)\n",
    "            a = a[mask].to(torch.int64)\n",
    "            b = b[mask].to(torch.int64)\n",
    "            indices = n * a + b\n",
    "            counts = torch.bincount(indices, minlength=n ** 2)\n",
    "            self.mat += counts.reshape(n, n)\n",
    "\n",
    "    def reset(self):\n",
    "        self.mat.zero_()\n",
    "\n",
    "    def compute(self):\n",
    "        h = self.mat.float()\n",
    "        diag_sum = torch.diag(h).sum()\n",
    "        total_sum = h.sum()\n",
    "        acc_global = (diag_sum / total_sum).item() if total_sum > 0 else 0.0\n",
    "        se = (h[1, 1] / h[1].sum()).item() if h[1].sum() > 0 else 0.0\n",
    "        sp = (h[0, 0] / h[0].sum()).item() if h[0].sum() > 0 else 0.0\n",
    "        pr = (h[1, 1] / h[:, 1].sum()).item() if h[:, 1].sum() > 0 else 0.0\n",
    "        F1 = 2 * (pr * se) / (pr + se) if (pr + se) > 0 else 0.0\n",
    "        return acc_global, se, sp, F1, pr\n",
    "\n",
    "def evaluate(model, data_loader, num_classes):\n",
    "    model.eval()\n",
    "    confmat = ConfusionMatrix(num_classes,device=\"cuda\")\n",
    "    data_loader = tqdm(data_loader)\n",
    "    mask = None\n",
    "    predict = None\n",
    "    dice_c = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            for image, target, eye_masks in data:\n",
    "                image, target = image.cuda(), target.cuda()\n",
    "                output = model(image)\n",
    "                if type(output) is list:\n",
    "                    output = output[0]\n",
    "                output = torch.sigmoid(output)\n",
    "                truth = output.clone()\n",
    "                output[output >= 0.5] = 1\n",
    "                output[output < 0.5] = 0\n",
    "                confmat.update(target.flatten(), output.long().flatten())\n",
    "                dice_c += dice_coeff(output, target)\n",
    "                mask = target.flatten() if mask is None else torch.cat((mask, target.flatten()))\n",
    "                predict = truth.flatten() if predict is None else torch.cat((predict, truth.flatten()))\n",
    "\n",
    "    mask = mask.cpu().numpy()\n",
    "    predict = predict.cpu().numpy()\n",
    "    AUC_ROC = roc_auc_score(mask, predict)\n",
    "    iou = calculate_iou(model,data_loader)\n",
    "    return confmat.compute()[0], confmat.compute()[1], confmat.compute()[2], confmat.compute()[3], confmat.compute()[\n",
    "        4], AUC_ROC, dice_c / len(data_loader), iou\n",
    "\n",
    "    \n",
    "def dice_coeff(x: torch.Tensor, target: torch.Tensor, epsilon=1e-6):\n",
    "    d = 0.\n",
    "    batch_size = x.shape[0]\n",
    "    for i in range(batch_size):\n",
    "        x_i = x[i].reshape(-1)\n",
    "        t_i = target[i].reshape(-1).float()\n",
    "        inter = torch.dot(x_i, t_i)\n",
    "        sets_sum = torch.sum(x_i) + torch.sum(t_i)\n",
    "        if sets_sum == 0:\n",
    "            sets_sum = 2 * inter\n",
    "        d += (2 * inter + epsilon) / (sets_sum + epsilon)\n",
    "    return d / batch_size\n",
    "    \n",
    "def calculate_iou1(y_true, y_pred, labels=[0, 1]):\n",
    "    IoU_scores = []\n",
    "    for label in labels:\n",
    "        jaccard = jaccard_score(y_true.flatten().cpu().numpy(), y_pred.flatten().cpu().numpy(), pos_label=label, average='weighted')\n",
    "        IoU_scores.append(jaccard)     \n",
    "    return torch.tensor(IoU_scores).mean().item()\n",
    "    \n",
    "def calculate_iou(model, dataloader):\n",
    "    model.eval()\n",
    "    total_iou = 0.0\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            z = len(data)\n",
    "            for images, masks, eye_masks in data:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Convert outputs to binary predictions\n",
    "                binary_preds = (outputs > 0.5).float()\n",
    "                \n",
    "                # Calculate intersection and union\n",
    "                intersection = torch.logical_and(binary_preds, masks).sum((1, 2))  # Sum over height and width\n",
    "                union = torch.logical_or(binary_preds, masks).sum((1, 2))         # Sum over height and width\n",
    "                \n",
    "                # Calculate IOU for each sample in the batch\n",
    "                iou_per_sample = torch.where(union == 0, torch.ones_like(union), intersection.float() / union.float())\n",
    "                \n",
    "                # Average IOU across the batch\n",
    "                batch_iou = iou_per_sample.mean().item()\n",
    "                total_iou += batch_iou\n",
    "    \n",
    "    # Calculate average IOU across all batches\n",
    "    avg_iou = total_iou / (num_batches*z)\n",
    "    return avg_iou\n",
    "\n",
    "def get_metrics(predict, target, threshold=0.5, predict_b=None):\n",
    "    predict = torch.sigmoid(predict).cpu().detach().numpy().flatten()\n",
    "    if predict_b is not None:\n",
    "        predict_b = predict_b.flatten()\n",
    "    else:\n",
    "        predict_b = np.where(predict >= threshold, 1, 0)\n",
    "    if torch.is_tensor(target):\n",
    "        target = target.cpu().detach().numpy().flatten()\n",
    "    else:\n",
    "        target = target.flatten()\n",
    "    tp = (predict_b * target).sum()\n",
    "    tn = ((1 - predict_b) * (1 - target)).sum()\n",
    "    fp = ((1 - target) * predict_b).sum()\n",
    "    fn = ((1 - predict_b) * target).sum()\n",
    "    auc = roc_auc_score(target, predict)\n",
    "    acc = (tp + tn) / (tp + fp + fn + tn)\n",
    "    pre = tp / (tp + fp)\n",
    "    sen = tp / (tp + fn)\n",
    "    spe = tn / (tn + fp)\n",
    "    iou = tp / (tp + fp + fn)\n",
    "    f1 = 2 * pre * sen / (pre + sen)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ef646b-0481-48e5-adda-67a07dc206ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T02:07:54.864958Z",
     "iopub.status.busy": "2024-04-27T02:07:54.864832Z",
     "iopub.status.idle": "2024-04-27T02:07:55.250717Z",
     "shell.execute_reply": "2024-04-27T02:07:55.250411Z",
     "shell.execute_reply.started": "2024-04-27T02:07:54.864949Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import v2\n",
    "from PIL import Image\n",
    "import torchsummary\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision.utils\n",
    "# from train_utils.train_and_eval import train_one_epoch, evaluate, create_lr_scheduler\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "\n",
    "    return inp\n",
    "    \n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None,windows_size=(128,128),stride=(32,32)):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.window_size = windows_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.image_dir = os.path.join(root_dir,'images')\n",
    "        self.mask_dir = os.path.join(root_dir,'1st_manual')\n",
    "        self.eye_mask_dir = os.path.join(root_dir,'mask')\n",
    "        \n",
    "        self.image_filenames = os.listdir(self.image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_filenames[idx]\n",
    "        image_path = os.path.join(self.image_dir,image_name)\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        patches_image = self.extract_patches(image)\n",
    "        \n",
    "        mask_name = image_name.replace(\"training.tif\",\"manual1.gif\")\n",
    "        mask_path = os.path.join(self.mask_dir,mask_name)\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        patches_mask = self.extract_patches(mask)\n",
    "        \n",
    "\n",
    "        eye_mask_name = image_name.replace(\".tif\",\"_mask.gif\")\n",
    "        eye_mask_path = os.path.join(self.eye_mask_dir,eye_mask_name)\n",
    "        eye_mask = Image.open(eye_mask_path).convert('L')\n",
    "        patches_eye_mask = self.extract_patches(eye_mask)\n",
    "\n",
    "        data = []\n",
    "        if self.transform:\n",
    "            for patch1,patch2,patch3 in zip(patches_image,patches_mask,patches_eye_mask):\n",
    "                data.append((self.transform(patch1),self.transform(patch2),self.transform(patch3)))\n",
    "\n",
    "        return data\n",
    "\n",
    "    def extract_patches(self, image):\n",
    "        patches = []\n",
    "        width, height = image.size\n",
    "        window_height, window_width = self.window_size\n",
    "        stride_vertical, stride_horizontal = self.stride\n",
    "\n",
    "        for y in range(0, height - window_height + 1, stride_vertical):\n",
    "            for x in range(0, width - window_width + 1, stride_horizontal):\n",
    "                patch = image.crop((x, y, x + window_width, y + window_height))\n",
    "                patches.append(patch)\n",
    "\n",
    "        return patches\n",
    "\n",
    "transform = v2.Compose([\n",
    "    # v2.Resize((224,224)),\n",
    "    # v2.RandomRotation(degrees=(0,180)),\n",
    "    v2.Compose([v2.ToImage(),v2.ToDtype(torch.float32,scale=True)]),\n",
    "    # v2.Normalize([0.485], [0.229]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17de1170-a32f-4fd0-8475-1e53726a4fb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T02:07:55.252218Z",
     "iopub.status.busy": "2024-04-27T02:07:55.252138Z",
     "iopub.status.idle": "2024-04-27T02:07:55.254326Z",
     "shell.execute_reply": "2024-04-27T02:07:55.253993Z",
     "shell.execute_reply.started": "2024-04-27T02:07:55.252209Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(root_dir=\"./training\",transform=transform)\n",
    "val_dataset = CustomDataset(root_dir=\"./validation\",transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=False)\n",
    "val_loader = DataLoader(val_dataset,batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c78cf15-c785-4542-9ffa-e07e319c35e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T02:07:55.254996Z",
     "iopub.status.busy": "2024-04-27T02:07:55.254769Z",
     "iopub.status.idle": "2024-04-27T02:07:55.264412Z",
     "shell.execute_reply": "2024-04-27T02:07:55.263951Z",
     "shell.execute_reply.started": "2024-04-27T02:07:55.254983Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.ModuleList([\n",
    "            DoubleConv(in_channels, 64),\n",
    "            DoubleConv(64, 128),\n",
    "            DoubleConv(128, 256),\n",
    "            DoubleConv(256, 512),\n",
    "            DoubleConv(512, 1024)\n",
    "        ])\n",
    "        \n",
    "        self.decoder = nn.ModuleList([\n",
    "            DoubleConv(1024 + 512, 512),  # Adjusted for concatenation\n",
    "            DoubleConv(512 + 256, 256),   # Adjusted for concatenation\n",
    "            DoubleConv(256 + 128, 128),   # Adjusted for concatenation\n",
    "            DoubleConv(128 + 64, 64),     # Adjusted for concatenation\n",
    "        ])\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        encoder_outputs = []\n",
    "        for encoder in self.encoder:\n",
    "            x = encoder(x)\n",
    "            encoder_outputs.append(x)\n",
    "            x = nn.MaxPool2d(kernel_size=2)(x)\n",
    "        x = self.upsample(x)\n",
    "        # Decoder\n",
    "        for i, (decoder, encoder_output) in enumerate(zip(self.decoder, reversed(encoder_outputs[:-1]))):\n",
    "            # print(x.shape)\n",
    "            x = self.upsample(x)\n",
    "            # print(f\"Shape of x after upsampling in decoder {i+1}: {x.shape}\")\n",
    "            x = torch.cat([x, encoder_output], dim=1)\n",
    "            x = decoder(x)\n",
    "        \n",
    "        # Final Convolution\n",
    "        x = self.final_conv(x)\n",
    "        # x = torch.sigmoid(x)  # Assuming binary segmentation\n",
    "        return x\n",
    "\n",
    "    # def upsample(self, x):\n",
    "    #     return nn.ConvTranspose2d(x.shape[1], x.shape[1], kernel_size=2, stride=2).forward(x).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bdaa7c-d531-4e96-bd98-92a1665b7dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-27T02:07:55.264870Z",
     "iopub.status.busy": "2024-04-27T02:07:55.264781Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbattulasaikiran2002\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/saikiranbattula/Desktop/sai files/Project Deep Learning/wandb/run-20240426_220756-qz8rzxwp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/battulasaikiran2002/Unet%20model/runs/qz8rzxwp' target=\"_blank\">fiery-galaxy-32</a></strong> to <a href='https://wandb.ai/battulasaikiran2002/Unet%20model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/battulasaikiran2002/Unet%20model' target=\"_blank\">https://wandb.ai/battulasaikiran2002/Unet%20model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/battulasaikiran2002/Unet%20model/runs/qz8rzxwp' target=\"_blank\">https://wandb.ai/battulasaikiran2002/Unet%20model/runs/qz8rzxwp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy attained: 90.4111%\n",
      "Epoch [1/100], Loss: 51.6498, Accuracy: 90.4111%, IOU: 0.4858096198666663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy attained: 93.1440%\n",
      "Epoch [2/100], Loss: 36.9695, Accuracy: 93.1440%, IOU: 0.44009455499194916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy attained: 93.8739%\n",
      "Epoch [3/100], Loss: 32.5368, Accuracy: 93.8739%, IOU: 0.4714545215879168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy attained: 93.9483%\n",
      "Epoch [4/100], Loss: 30.4811, Accuracy: 93.9483%, IOU: 0.5591428765228816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "train_iou_history = []\n",
    "val_iou_history = []\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = UNet(in_channels=1, out_channels=1).to('cuda')\n",
    "model = model.cuda()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "logs = wandb.init(project=\"Unet model\")\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "num_epochs = 100 \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        for images, masks, eye_masks in data:\n",
    "            images = images.cuda()\n",
    "            masks = masks.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    acc, se, sp, F1, pr, AUC_ROC, dice, iou = evaluate(model, val_loader, num_classes=2)\n",
    "    # IOU = []\n",
    "    # for data in val_loader:\n",
    "    #     for images, masks, eye_masks in data:\n",
    "    #         images = images.cuda()\n",
    "    #         masks = masks.cuda()\n",
    "\n",
    "    #         model.eval()\n",
    "    #         outputs = model(images)\n",
    "    #         outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "    #         iou = get_metrics(outputs,masks)\n",
    "    #         IOU.append(iou)\n",
    "    # print(np.mean(IOU))\n",
    "    logs.log({\n",
    "        \"acc\": acc,\n",
    "        \"sensitivity\": se,\n",
    "        \"specificity\": sp,\n",
    "        \"F1-score\": F1,\n",
    "        \"AUC_ROC\": AUC_ROC,\n",
    "        \"Dice\": dice,\n",
    "        \"epoch\": epoch,\n",
    "        \"IOU\": iou\n",
    "    })\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        print(f\"Best accuracy attained: {best_acc*100:.4f}%\")\n",
    "        torch.save(model.state_dict(),\"unet_model.pth\")\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {acc*100:.4f}%, IOU: {iou}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868846b-2349-41f6-97db-1a3129c782be",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-27T01:58:26.052163Z",
     "iopub.status.idle": "2024-04-27T01:58:26.052326Z",
     "shell.execute_reply": "2024-04-27T01:58:26.052254Z",
     "shell.execute_reply.started": "2024-04-27T01:58:26.052247Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(),\"unet_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5543c43-ba85-4ce8-b67c-0789a73e3392",
   "metadata": {
    "execution": {
     "execution_failed": "2024-04-27T01:25:27.571Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "input_image = Image.open('15_test.tif').convert('L')  \n",
    "input_tensor = transform(input_image).unsqueeze(0) \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor.cuda())\n",
    "\n",
    "output = torch.sigmoid(output)\n",
    "predicted_mask = (output > 0.5).float()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(input_image,cmap='gray')\n",
    "plt.title('Input Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(predicted_mask.squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.title('Predicted Mask')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5427fa-e944-458d-87d9-bb7d8ad102e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
